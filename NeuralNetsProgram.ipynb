{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "import seaborn as seabornInstance \n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD, Adam,RMSprop, Adagrad\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=[\"X1\", \"X2\", \"X3\", \"X4\",\"X5\",\"Y\"]\n",
    "dataset = pd.read_csv('ytrived.csv',names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Get column names first\n",
    "names = dataset.columns\n",
    "# Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Fit your data on the scaler object\n",
    "scaled_df = scaler.fit_transform(dataset)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=names)\n",
    "\n",
    "train= scaled_df[:2000]\n",
    "test = scaled_df [2001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1046.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 20 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:51:47</td>     <th>  Log-Likelihood:    </th> <td> -1552.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2000</td>      <th>  AIC:               </th> <td>   3116.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1994</td>      <th>  BIC:               </th> <td>   3150.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0005</td> <td>    0.012</td> <td>    0.044</td> <td> 0.965</td> <td>   -0.023</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>    0.6569</td> <td>    0.012</td> <td>   55.792</td> <td> 0.000</td> <td>    0.634</td> <td>    0.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    0.1551</td> <td>    0.012</td> <td>   13.199</td> <td> 0.000</td> <td>    0.132</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>        <td>    0.1695</td> <td>    0.012</td> <td>   14.211</td> <td> 0.000</td> <td>    0.146</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>        <td>    0.2942</td> <td>    0.012</td> <td>   24.719</td> <td> 0.000</td> <td>    0.271</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X5</th>        <td>    0.3813</td> <td>    0.012</td> <td>   32.234</td> <td> 0.000</td> <td>    0.358</td> <td>    0.405</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1257.481</td> <th>  Durbin-Watson:     </th> <td>   2.005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>15928.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.789</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>15.650</td>  <th>  Cond. No.          </th> <td>    1.07</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.724\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     1046.\n",
       "Date:                Wed, 20 Nov 2019   Prob (F-statistic):               0.00\n",
       "Time:                        23:51:47   Log-Likelihood:                -1552.0\n",
       "No. Observations:                2000   AIC:                             3116.\n",
       "Df Residuals:                    1994   BIC:                             3150.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0005      0.012      0.044      0.965      -0.023       0.024\n",
       "X1             0.6569      0.012     55.792      0.000       0.634       0.680\n",
       "X2             0.1551      0.012     13.199      0.000       0.132       0.178\n",
       "X3             0.1695      0.012     14.211      0.000       0.146       0.193\n",
       "X4             0.2942      0.012     24.719      0.000       0.271       0.318\n",
       "X5             0.3813      0.012     32.234      0.000       0.358       0.405\n",
       "==============================================================================\n",
       "Omnibus:                     1257.481   Durbin-Watson:                   2.005\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            15928.118\n",
       "Skew:                           2.789   Prob(JB):                         0.00\n",
       "Kurtosis:                      15.650   Cond. No.                         1.07\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr = smf.ols(formula='Y ~ X1 + X2 + X3 + X4 + X5 ', data=train).fit()\n",
    "mlr.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=mlr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "yactual=test['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.89506636431311\n"
     ]
    }
   ],
   "source": [
    "sse=0\n",
    "for i in range (2001,2300):\n",
    "    e= ypred[i]-yactual[i]\n",
    "    error= e*e\n",
    "    sse+= error\n",
    "print(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#The model obained after performing grid search. \n",
    "columns = ['X1', 'X2', 'X3', 'X4', 'X5']\n",
    "train=scaled_df[:2000]\n",
    "test=scaled_df[2001:]\n",
    "\n",
    "columns = ['X1', 'X2', 'X3', 'X4', 'X5']\n",
    "X_train = train[columns].values\n",
    "y_train = train[\"Y\"]\n",
    "X_test = test[columns].values\n",
    "y_test = test[\"Y\"]\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "print(input_dim)\n",
    "\n",
    "def create_model(activation='relu',dropout_rate=0.01,lr = 0.01,nodes=24):\n",
    "    optimizer= optimizers.Adam(lr=0.001)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=input_dim,   activation='relu'))\n",
    "    \n",
    "    model.add(Dense(24, activation='relu',kernel_regularizer=regularizers.l2(0.0)))\n",
    "    model.add(Dropout(0.001))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=4, epochs=80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.4188\n",
      "Epoch 2/80\n",
      "2000/2000 [==============================] - 1s 430us/step - loss: 0.2002\n",
      "Epoch 3/80\n",
      "2000/2000 [==============================] - 1s 480us/step - loss: 0.1105\n",
      "Epoch 4/80\n",
      "2000/2000 [==============================] - 1s 355us/step - loss: 0.0645\n",
      "Epoch 5/80\n",
      "2000/2000 [==============================] - 1s 443us/step - loss: 0.0448\n",
      "Epoch 6/80\n",
      "2000/2000 [==============================] - 1s 363us/step - loss: 0.0364\n",
      "Epoch 7/80\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.0295\n",
      "Epoch 8/80\n",
      "2000/2000 [==============================] - 1s 362us/step - loss: 0.0250\n",
      "Epoch 9/80\n",
      "2000/2000 [==============================] - 1s 355us/step - loss: 0.0206\n",
      "Epoch 10/80\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.0158\n",
      "Epoch 11/80\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 0.0128\n",
      "Epoch 12/80\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 0.0104\n",
      "Epoch 13/80\n",
      "2000/2000 [==============================] - 1s 368us/step - loss: 0.0083\n",
      "Epoch 14/80\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.0067\n",
      "Epoch 15/80\n",
      "2000/2000 [==============================] - 1s 360us/step - loss: 0.0059\n",
      "Epoch 16/80\n",
      "2000/2000 [==============================] - 1s 356us/step - loss: 0.0046\n",
      "Epoch 17/80\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 0.0040\n",
      "Epoch 18/80\n",
      "2000/2000 [==============================] - 1s 377us/step - loss: 0.0033\n",
      "Epoch 19/80\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.0024\n",
      "Epoch 20/80\n",
      "2000/2000 [==============================] - 1s 359us/step - loss: 0.0023\n",
      "Epoch 21/80\n",
      "2000/2000 [==============================] - 1s 377us/step - loss: 0.0021\n",
      "Epoch 22/80\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 0.0021\n",
      "Epoch 23/80\n",
      "2000/2000 [==============================] - 1s 413us/step - loss: 0.0020\n",
      "Epoch 24/80\n",
      "2000/2000 [==============================] - 1s 489us/step - loss: 0.0014\n",
      "Epoch 25/80\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.0016\n",
      "Epoch 26/80\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.0015\n",
      "Epoch 27/80\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 0.0024\n",
      "Epoch 28/80\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 0.0012\n",
      "Epoch 29/80\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 0.0018\n",
      "Epoch 30/80\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.0012\n",
      "Epoch 31/80\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.0011\n",
      "Epoch 32/80\n",
      "2000/2000 [==============================] - 1s 363us/step - loss: 0.0015\n",
      "Epoch 33/80\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.0020\n",
      "Epoch 34/80\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 8.4137e-04\n",
      "Epoch 35/80\n",
      "2000/2000 [==============================] - 1s 497us/step - loss: 8.0490e-04\n",
      "Epoch 36/80\n",
      "2000/2000 [==============================] - 1s 548us/step - loss: 9.1392e-04\n",
      "Epoch 37/80\n",
      "2000/2000 [==============================] - 1s 481us/step - loss: 0.0012\n",
      "Epoch 38/80\n",
      "2000/2000 [==============================] - 1s 602us/step - loss: 9.8789e-04\n",
      "Epoch 39/80\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.0018\n",
      "Epoch 40/80\n",
      "2000/2000 [==============================] - 1s 433us/step - loss: 8.5481e-04\n",
      "Epoch 41/80\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 7.7804e-04\n",
      "Epoch 42/80\n",
      "2000/2000 [==============================] - 1s 514us/step - loss: 6.2841e-04\n",
      "Epoch 43/80\n",
      "2000/2000 [==============================] - 1s 509us/step - loss: 5.9737e-04\n",
      "Epoch 44/80\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 9.3667e-04\n",
      "Epoch 45/80\n",
      "2000/2000 [==============================] - 1s 395us/step - loss: 0.0014\n",
      "Epoch 46/80\n",
      "2000/2000 [==============================] - 1s 750us/step - loss: 8.5923e-04\n",
      "Epoch 47/80\n",
      "2000/2000 [==============================] - 1s 448us/step - loss: 5.3653e-04\n",
      "Epoch 48/80\n",
      "2000/2000 [==============================] - 1s 357us/step - loss: 5.9631e-04\n",
      "Epoch 49/80\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.0012\n",
      "Epoch 50/80\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 5.6223e-04\n",
      "Epoch 51/80\n",
      "2000/2000 [==============================] - 1s 358us/step - loss: 7.4384e-04\n",
      "Epoch 52/80\n",
      "2000/2000 [==============================] - 1s 395us/step - loss: 0.0010\n",
      "Epoch 53/80\n",
      "2000/2000 [==============================] - 1s 339us/step - loss: 0.0010\n",
      "Epoch 54/80\n",
      "2000/2000 [==============================] - 1s 342us/step - loss: 0.0014\n",
      "Epoch 55/80\n",
      "2000/2000 [==============================] - 1s 639us/step - loss: 5.3032e-04\n",
      "Epoch 56/80\n",
      "2000/2000 [==============================] - 1s 617us/step - loss: 4.1914e-04\n",
      "Epoch 57/80\n",
      "2000/2000 [==============================] - 2s 829us/step - loss: 9.2131e-04\n",
      "Epoch 58/80\n",
      "2000/2000 [==============================] - 1s 543us/step - loss: 7.1179e-04\n",
      "Epoch 59/80\n",
      "2000/2000 [==============================] - 1s 622us/step - loss: 8.0173e-04\n",
      "Epoch 60/80\n",
      "2000/2000 [==============================] - 1s 615us/step - loss: 0.0010\n",
      "Epoch 61/80\n",
      "2000/2000 [==============================] - 1s 638us/step - loss: 5.4180e-04\n",
      "Epoch 62/80\n",
      "2000/2000 [==============================] - 1s 514us/step - loss: 6.2319e-04\n",
      "Epoch 63/80\n",
      "2000/2000 [==============================] - 1s 488us/step - loss: 5.9808e-04\n",
      "Epoch 64/80\n",
      "2000/2000 [==============================] - 1s 509us/step - loss: 5.2471e-04\n",
      "Epoch 65/80\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 4.5428e-04\n",
      "Epoch 66/80\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 7.9220e-04\n",
      "Epoch 67/80\n",
      "2000/2000 [==============================] - 1s 365us/step - loss: 8.1011e-04\n",
      "Epoch 68/80\n",
      "2000/2000 [==============================] - 1s 346us/step - loss: 7.9473e-04\n",
      "Epoch 69/80\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 8.5181e-04\n",
      "Epoch 70/80\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 8.2766e-04\n",
      "Epoch 71/80\n",
      "2000/2000 [==============================] - 1s 356us/step - loss: 6.5772e-04\n",
      "Epoch 72/80\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 9.7937e-04\n",
      "Epoch 73/80\n",
      "2000/2000 [==============================] - 1s 396us/step - loss: 0.0014\n",
      "Epoch 74/80\n",
      "2000/2000 [==============================] - 1s 619us/step - loss: 5.2712e-04\n",
      "Epoch 75/80\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 6.9587e-04\n",
      "Epoch 76/80\n",
      "2000/2000 [==============================] - 1s 594us/step - loss: 4.7334e-04\n",
      "Epoch 77/80\n",
      "2000/2000 [==============================] - 1s 641us/step - loss: 0.0010\n",
      "Epoch 78/80\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 0.0018\n",
      "Epoch 79/80\n",
      "2000/2000 [==============================] - 1s 480us/step - loss: 6.5352e-04\n",
      "Epoch 80/80\n",
      "2000/2000 [==============================] - 1s 590us/step - loss: 8.6932e-04\n"
     ]
    }
   ],
   "source": [
    "fitt= model.fit(X_train,y_train)\n",
    "ypred_nn= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=fitt.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig4=plt.figure()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot( loss)\n",
    "plt.xlabel(\"Ephocs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15090837631543597\n"
     ]
    }
   ],
   "source": [
    "sse=0\n",
    "error=0\n",
    "for i in range(0,299):\n",
    "    #print(ypred[i])\n",
    "    #print(y_test[i+2001])\n",
    "    e= ypred_nn[i]-y_test[i+2001]\n",
    "    error= e*e\n",
    "    sse += error\n",
    "print(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashad\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-f0039c73e07b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m##############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;31m##############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m# summarize results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid search code, ran on the dataspace machines.\n",
    "\"\"\"\n",
    "Created on Sun Nov 17 20:41:09 2019\n",
    "\n",
    "@author: Yashad\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD, Adam,RMSprop, Adagrad\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "col_names=[\"X1\", \"X2\", \"X3\", \"X4\",\"X5\",\"Y\"]\n",
    "df = pd.read_csv('ytrived.csv',names=col_names)\n",
    "\n",
    "columns = ['X1', 'X2', 'X3', 'X4', 'X5']\n",
    "train=df[:2000]\n",
    "test=df[2001:]\n",
    "\n",
    "X_train = train[columns].values\n",
    "y_train = train[\"Y\"]\n",
    "X_test = test[columns].values\n",
    "y_test = test[\"Y\"]\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "print(input_dim)\n",
    "\n",
    "def create_model(activation='relu',dropout_rate=0.0,lr = 0.01,nodes=5,l2_regularizer=0.0):\n",
    "\n",
    "    init_mode='uniform'\n",
    "\n",
    "    optimizer= optimizers.Adam(lr=lr)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=input_dim, kernel_initializer=init_mode,  \n",
    "                    activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(nodes, kernel_initializer=init_mode, activation=activation,kernel_regularizer=regularizers.l2(l2_regularizer)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=10, epochs=10)\n",
    "activation =  ['relu', 'tanh', 'sigmoid']\n",
    "learn_rate = [0.001, 0.01,0.1, 0.2, 0.3]\n",
    "dropout_rate = [0.001,0.01,0.1, 0.2,0.3]\n",
    "nodes=[8,16,24,32]\n",
    "l2_regularizer = [0.0,0.1,0.2]\n",
    "\n",
    "epochs = [50,80] \n",
    "batch_size = [4,8, 16, 24,32,64] \n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size,activation=activation,dropout_rate=dropout_rate,\n",
    "                  lr=learn_rate, nodes=nodes,l2_regularizer=l2_regularizer)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train,verbose=0) \n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
